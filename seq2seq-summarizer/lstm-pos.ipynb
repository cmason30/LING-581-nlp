{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7134eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa7b0aa21d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a602a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up an LSTM as a basic tutorial. A top-down approach. \n",
    "\n",
    "# Tutorial found on PyTorch: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "lstm = nn.LSTM(3, 3) # Set input im as 3 and output dim as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d654eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.5525,  0.6355, -0.3968]]),\n",
       " tensor([[-0.6571, -1.6428,  0.9803]]),\n",
       " tensor([[-0.0421, -0.8206,  0.3133]]),\n",
       " tensor([[-1.1352,  0.3773, -0.2824]]),\n",
       " tensor([[-2.5667, -1.4303,  0.5009]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [torch.randn(1,3) for _ in range(5)]\n",
    "inputs # Sequence of length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe58e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2682,  0.0304, -0.1526]]], grad_fn=<StackBackward0>) (tensor([[[-0.2682,  0.0304, -0.1526]]], grad_fn=<StackBackward0>), tensor([[[-1.0766,  0.0972, -0.5498]]], grad_fn=<StackBackward0>))\n",
      "tensor([[[-0.5370,  0.0346, -0.1958]]], grad_fn=<StackBackward0>) (tensor([[[-0.5370,  0.0346, -0.1958]]], grad_fn=<StackBackward0>), tensor([[[-1.1552,  0.1214, -0.2974]]], grad_fn=<StackBackward0>))\n",
      "tensor([[[-0.3947,  0.0391, -0.1217]]], grad_fn=<StackBackward0>) (tensor([[[-0.3947,  0.0391, -0.1217]]], grad_fn=<StackBackward0>), tensor([[[-1.0727,  0.1104, -0.2179]]], grad_fn=<StackBackward0>))\n",
      "tensor([[[-0.1854,  0.0740, -0.0979]]], grad_fn=<StackBackward0>) (tensor([[[-0.1854,  0.0740, -0.0979]]], grad_fn=<StackBackward0>), tensor([[[-1.0530,  0.1836, -0.1731]]], grad_fn=<StackBackward0>))\n",
      "tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward0>) (tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward0>), tensor([[[-1.1298,  0.4467,  0.0254]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "hidden = (torch.randn(1,1,3),\n",
    "          torch.randn(1,1,3))\n",
    "\n",
    "for ii in inputs:\n",
    "    # Step through the sequence one element at a time\n",
    "    # Hidden contains hidden state after each step\n",
    "    out, hidden = lstm(ii.view(1,1,-1), hidden) \n",
    "    print(out, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f8a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an LSTM for POS tagging\n",
    "\n",
    "def prep_seq(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6161b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = zip_object[1:100]\n",
    "word_to_ix = {}\n",
    "\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:  \n",
    "            word_to_ix[word] = len(word_to_ix)  \n",
    "#print(word_to_ix)\n",
    "tag_to_ix = {\"ADJ\": 0, \"ADP\": 1, \"ADV\": 2, \"CONJ\":3, \"DET\":4, \"NOUN\":5, \"NUM\":6, \"PRT\":7, \"PRON\":8,\n",
    "             \"VERB\":9, \".\":10, \"X\":11}\n",
    "\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1d8d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34b79d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3495, -2.2596, -2.6705, -2.8485, -2.2588, -2.8152, -2.5928, -2.8620,\n",
      "         -2.1860, -2.4379, -2.4248, -2.4247],\n",
      "        [-2.2112, -2.2662, -2.6749, -2.9363, -2.3828, -2.7587, -2.7073, -2.9391,\n",
      "         -2.1649, -2.4900, -2.3206, -2.3691],\n",
      "        [-2.3951, -2.3126, -2.7538, -2.7509, -2.2297, -2.7975, -2.6108, -2.8141,\n",
      "         -2.2154, -2.3957, -2.4084, -2.4064],\n",
      "        [-2.3913, -2.1993, -2.5799, -2.9197, -2.2754, -2.8156, -2.5082, -2.9434,\n",
      "         -2.1399, -2.4680, -2.4516, -2.4940],\n",
      "        [-2.4136, -2.2777, -2.6898, -2.8358, -2.1953, -2.8558, -2.5945, -2.7952,\n",
      "         -2.2150, -2.3867, -2.3995, -2.4658],\n",
      "        [-2.4158, -2.2605, -2.6351, -2.8462, -2.2117, -2.8272, -2.5450, -2.8392,\n",
      "         -2.1799, -2.4229, -2.4395, -2.5002],\n",
      "        [-2.3626, -2.1972, -2.5301, -2.9704, -2.3089, -2.7904, -2.5379, -2.9664,\n",
      "         -2.0923, -2.5040, -2.4166, -2.5497],\n",
      "        [-2.4242, -2.2510, -2.5840, -2.8824, -2.2458, -2.7855, -2.5346, -2.8901,\n",
      "         -2.1271, -2.4513, -2.4070, -2.5662],\n",
      "        [-2.5260, -2.3721, -2.7483, -2.6898, -2.1391, -2.7815, -2.5317, -2.7557,\n",
      "         -2.2547, -2.3387, -2.4082, -2.5174],\n",
      "        [-2.5882, -2.3883, -2.8244, -2.6242, -2.1168, -2.7907, -2.4953, -2.7554,\n",
      "         -2.3114, -2.2927, -2.4254, -2.4675],\n",
      "        [-2.4442, -2.2328, -2.6537, -2.8286, -2.2075, -2.8491, -2.5017, -2.8640,\n",
      "         -2.1929, -2.4149, -2.4842, -2.4619],\n",
      "        [-2.5134, -2.2424, -2.6655, -2.7803, -2.1926, -2.8195, -2.4102, -2.9001,\n",
      "         -2.2232, -2.3941, -2.5195, -2.4637],\n",
      "        [-2.3919, -2.2916, -2.7909, -2.8165, -2.2577, -2.8185, -2.6208, -2.8592,\n",
      "         -2.2715, -2.3518, -2.3242, -2.3465],\n",
      "        [-2.4648, -2.3917, -2.8780, -2.6608, -2.1455, -2.8482, -2.6812, -2.6791,\n",
      "         -2.2957, -2.3072, -2.3632, -2.3974],\n",
      "        [-2.3984, -2.4342, -2.8516, -2.7082, -2.1999, -2.7707, -2.7352, -2.7050,\n",
      "         -2.2860, -2.3260, -2.2611, -2.4272],\n",
      "        [-2.4239, -2.4579, -2.8817, -2.6540, -2.1698, -2.7831, -2.7545, -2.6552,\n",
      "         -2.2826, -2.3187, -2.2845, -2.4399],\n",
      "        [-2.2666, -2.3177, -2.7577, -2.7327, -2.2737, -2.7976, -2.6876, -2.7969,\n",
      "         -2.1863, -2.4729, -2.4901, -2.3346],\n",
      "        [-2.3208, -2.3502, -2.7864, -2.7617, -2.2501, -2.7955, -2.7198, -2.7681,\n",
      "         -2.2215, -2.4022, -2.3516, -2.3825],\n",
      "        [-2.4643, -2.4032, -2.8567, -2.6207, -2.1460, -2.8081, -2.6210, -2.7008,\n",
      "         -2.2971, -2.3299, -2.4283, -2.3958],\n",
      "        [-2.3827, -2.3244, -2.7113, -2.7625, -2.2178, -2.7833, -2.5838, -2.8071,\n",
      "         -2.2214, -2.4095, -2.4321, -2.4355],\n",
      "        [-2.3824, -2.2855, -2.8226, -2.7920, -2.2645, -2.8339, -2.6496, -2.8503,\n",
      "         -2.2609, -2.3575, -2.3404, -2.3145],\n",
      "        [-2.3784, -2.3367, -2.8083, -2.7692, -2.2135, -2.8388, -2.6918, -2.7549,\n",
      "         -2.2599, -2.3545, -2.3379, -2.3791],\n",
      "        [-2.4041, -2.3636, -2.7847, -2.7391, -2.2099, -2.7877, -2.6643, -2.7604,\n",
      "         -2.2376, -2.3638, -2.3368, -2.4352],\n",
      "        [-2.5191, -2.4045, -2.8392, -2.6154, -2.1334, -2.7868, -2.5545, -2.7287,\n",
      "         -2.3082, -2.3141, -2.4296, -2.4295],\n",
      "        [-2.4065, -2.3546, -2.7182, -2.7613, -2.1993, -2.7733, -2.6011, -2.7784,\n",
      "         -2.2326, -2.3845, -2.3801, -2.4751]])\n",
      "tensor([[-2.4751e+00, -4.3091e+00, -3.9406e+00, -9.3667e+00, -2.6107e-01,\n",
      "         -3.3950e+00, -4.8142e+00, -2.8175e+00, -5.1238e+00, -5.3387e+00,\n",
      "         -8.5566e+00, -8.1172e+00],\n",
      "        [-3.4999e+00, -5.6478e+00, -4.7934e+00, -6.8977e+00, -1.0639e+01,\n",
      "         -9.8797e-02, -4.4894e+00, -7.5806e+00, -5.1620e+00, -3.4680e+00,\n",
      "         -6.1012e+00, -8.8603e+00],\n",
      "        [-2.3584e+00, -4.1104e+00, -1.8630e+00, -7.3353e+00, -8.5791e+00,\n",
      "         -2.6712e+00, -2.7493e+00, -8.3123e+00, -1.9380e+00, -7.9022e-01,\n",
      "         -6.3437e+00, -9.3898e+00],\n",
      "        [-6.4669e+00, -8.7929e+00, -5.5029e+00, -7.8483e+00, -8.2272e+00,\n",
      "         -6.7089e+00, -4.6771e+00, -1.0195e+01, -5.7503e+00, -2.9970e-02,\n",
      "         -4.6758e+00, -1.0680e+01],\n",
      "        [-7.6017e+00, -2.1197e-02, -4.2477e+00, -1.2407e+01, -1.1972e+01,\n",
      "         -1.3617e+01, -7.8195e+00, -7.0544e+00, -5.7665e+00, -6.3504e+00,\n",
      "         -1.0689e+01, -1.3324e+01],\n",
      "        [-3.4576e+00, -9.5923e+00, -4.2195e+00, -1.1025e+01, -5.7345e+00,\n",
      "         -2.3634e-01, -4.8057e+00, -7.7737e+00, -5.4515e+00, -1.9113e+00,\n",
      "         -8.8766e+00, -1.0188e+01],\n",
      "        [-3.1201e+00, -5.6132e+00, -3.4611e+00, -7.4534e+00, -1.0523e+01,\n",
      "         -4.8621e-01, -3.6960e+00, -8.0144e+00, -4.2096e+00, -1.3340e+00,\n",
      "         -6.3679e+00, -9.1836e+00],\n",
      "        [-4.9413e+00, -1.6433e-01, -2.3978e+00, -1.0533e+01, -1.0572e+01,\n",
      "         -8.9380e+00, -5.4454e+00, -6.1368e+00, -4.1286e+00, -3.4865e+00,\n",
      "         -9.3643e+00, -1.1294e+01],\n",
      "        [-6.9175e+00, -1.3072e+01, -1.1199e+01, -1.2783e+01, -1.8683e-03,\n",
      "         -7.3867e+00, -1.0096e+01, -1.0112e+01, -8.8246e+00, -1.4657e+01,\n",
      "         -1.2029e+01, -1.2792e+01],\n",
      "        [-2.6244e+00, -7.0745e+00, -5.3458e+00, -1.0238e+01, -9.4021e+00,\n",
      "         -1.0812e-01, -5.3618e+00, -6.7527e+00, -8.9135e+00, -4.0057e+00,\n",
      "         -1.3463e+01, -9.7628e+00],\n",
      "        [-1.6875e+00, -3.6261e+00, -3.0413e+00, -3.5049e+00, -3.5812e+00,\n",
      "         -2.4361e+00, -2.0630e+00, -6.6250e+00, -1.1455e+00, -2.8817e+00,\n",
      "         -2.3891e+00, -6.9089e+00],\n",
      "        [-3.2765e+00, -1.1762e+01, -5.3473e+00, -1.1974e+01, -7.1095e+00,\n",
      "         -1.1030e-01, -5.3271e+00, -1.0163e+01, -7.0936e+00, -2.8943e+00,\n",
      "         -1.2524e+01, -1.1375e+01],\n",
      "        [-9.5502e+00, -6.1984e+00, -7.6554e+00, -7.7583e+00, -8.8823e+00,\n",
      "         -9.1035e+00, -7.6715e+00, -8.3904e+00, -4.9588e+00, -6.1781e+00,\n",
      "         -1.3147e-02, -1.0976e+01],\n",
      "        [-6.1980e+00, -1.0166e+01, -9.0545e+00, -1.1558e+01, -5.9546e-03,\n",
      "         -6.2694e+00, -8.7731e+00, -7.6781e+00, -6.8308e+00, -1.2277e+01,\n",
      "         -8.9422e+00, -1.1323e+01],\n",
      "        [-2.2009e+00, -4.4019e+00, -3.5183e+00, -6.3176e+00, -9.5774e+00,\n",
      "         -8.5414e-01, -3.1045e+00, -6.6072e+00, -5.6201e+00, -9.9601e-01,\n",
      "         -7.8263e+00, -8.1315e+00],\n",
      "        [-3.8479e+00, -5.3127e+00, -4.3031e+00, -6.9648e+00, -1.0326e+01,\n",
      "         -8.5966e-01, -4.0286e+00, -6.1505e+00, -6.3546e+00, -6.7068e-01,\n",
      "         -5.9256e+00, -8.3634e+00],\n",
      "        [-3.4604e+00, -5.3867e+00, -3.2776e+00, -1.0472e+01, -5.5012e+00,\n",
      "         -1.7952e-01, -5.0444e+00, -3.9424e+00, -4.4780e+00, -3.0414e+00,\n",
      "         -6.5772e+00, -8.8824e+00],\n",
      "        [-6.9270e+00, -2.9334e-02, -4.7300e+00, -1.2158e+01, -8.1585e+00,\n",
      "         -1.0850e+01, -8.2758e+00, -4.4413e+00, -5.0383e+00, -9.0948e+00,\n",
      "         -8.7944e+00, -1.1878e+01],\n",
      "        [-6.5326e+00, -1.2743e+01, -1.1296e+01, -1.2077e+01, -2.7866e-03,\n",
      "         -6.8643e+00, -9.9048e+00, -9.9580e+00, -8.7825e+00, -1.5052e+01,\n",
      "         -1.1880e+01, -1.2378e+01],\n",
      "        [-4.3679e+00, -1.2836e+01, -8.0754e+00, -1.2369e+01, -1.1304e+01,\n",
      "         -1.5263e-02, -7.2862e+00, -1.2087e+01, -9.9076e+00, -6.5748e+00,\n",
      "         -1.5255e+01, -1.2577e+01],\n",
      "        [-8.9913e+00, -6.4796e+00, -7.6831e+00, -7.5151e+00, -7.6346e+00,\n",
      "         -8.3801e+00, -7.5024e+00, -8.2604e+00, -4.5933e+00, -6.8000e+00,\n",
      "         -1.5565e-02, -1.0651e+01],\n",
      "        [-1.0178e+01, -6.7829e+00, -8.8374e+00, -7.4844e+00, -4.9007e+00,\n",
      "         -1.1629e+01, -8.0707e+00, -7.2064e+00, -6.3797e+00, -6.8748e+00,\n",
      "         -1.3226e-02, -1.0519e+01],\n",
      "        [-3.7405e+00, -4.0585e+00, -3.4740e+00, -5.5363e+00, -9.4080e+00,\n",
      "         -1.7492e+00, -3.2804e+00, -6.2705e+00, -4.0330e+00, -4.3373e-01,\n",
      "         -3.1150e+00, -7.9156e+00],\n",
      "        [-7.3997e+00, -1.3179e+01, -1.1613e+01, -1.2698e+01, -1.2691e-03,\n",
      "         -7.7443e+00, -1.0413e+01, -1.0058e+01, -9.0034e+00, -1.5048e+01,\n",
      "         -1.1437e+01, -1.2823e+01],\n",
      "        [-3.3018e+00, -1.0079e+01, -6.3210e+00, -1.1290e+01, -9.3979e+00,\n",
      "         -4.7326e-02, -6.0883e+00, -9.6565e+00, -8.3360e+00, -5.3222e+00,\n",
      "         -1.3661e+01, -1.1190e+01]])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = prep_seq(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(100):  \n",
    "    for sentence, tags in training_data:\n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "\n",
    "        sentence_in = prep_seq(sentence, word_to_ix)\n",
    "        targets = prep_seq(tags, tag_to_ix)\n",
    "\n",
    "\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = prep_seq(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "030607fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up my own training data using NLTK\n",
    "\n",
    "b = nltk.corpus.brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed460ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb4ae7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['The', 'dog', 'ate', 'the', 'apple'], ['DET', 'NN', 'V', 'DET', 'NN']),\n",
       " (['Everybody', 'read', 'that', 'book'], ['NN', 'V', 'DET', 'NN'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9d5129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "778f8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_b = [item[0] for item in b]\n",
    "pos_b = [item[1] for item in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2eca7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_words = chunks(words_b, 25)\n",
    "chunk_pos = chunks(pos_b, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e741a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_object = list(zip(chunk_words, chunk_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a7aa18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = zip_object[1:1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LING581] *",
   "language": "python",
   "name": "conda-env-LING581-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
